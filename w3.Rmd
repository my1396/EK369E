---
title: "Equity Performance Evaluation"
author: "Menghan Yuan"
date: "March 27, 2024"
output: 
    bookdown::html_document2:
        toc: true
        toc_float: true
        toc_depth: 4
        number_sections: false
        css: style.css
bibliography: bibli.bib
link-citations: yes
biblio-style: apalike
editor_options: 
  chunk_output_type: console
---

```{r setup, include=F, echo=F}
library(knitr) # load packages
library(kableExtra)
library(tidyverse)
library(bookdown)
# don't show code unless we explicitly set echo = TRUE
opts_chunk$set(echo = TRUE, message=FALSE, fig.align="center", fig.pos = "H")
opts <- options(knitr.kable.NA = "")

## control long outputs by using eg `max.lines = 10`
hook_output_default <- knitr::knit_hooks$get('output')
truncate_to_lines <- function(x, n) {
   if (!is.null(n)) {
      x = unlist(stringr::str_split(x, '\n'))
      if (length(x) > n) {
         # truncate the output
         x = c(head(x, n), '...\n')
      }
      x = paste(x, collapse = '\n') # paste first n lines together
   }
   x
}
knitr::knit_hooks$set(output = function(x, options) {
   max.lines <- options$max.lines
   x <- truncate_to_lines(x, max.lines)
   hook_output_default(x, options)
})
```


## Return Concepts

### Simple returns

$r_t$ measures the rate of return from $t-1$ to $t$. 
It is the percentage change in price given by:

$$
r_t = \frac{P_t-P_{t-1}}{P_{t-1}} = \frac{P_t}{P_{t-1}}-1
$$

One commonly used equality is

$$
P_t = P_{t-1} (1+r_t)
$$


### Continuously compounded returns

$z_t$ measures the log return, also referred to as continuously compounded return.
It is the first difference of the natural logarithm of prices.

$$
z_t = \ln P_t - \ln P_{t-1} = \ln \frac{P_t}{P_{t-1}}
$$

The **conversion** between log return and simple return:

$$
\begin{aligned}
\color{red}{z_t} &\color{red}{= \ln (1+r_t) }\\
r_t &= e^{z_t} -1
\end{aligned}
$$

Q: Why is $z_t$ continuously compounded return?

A: This is related to the constant $e$, Euler number.

The discovery of the constant itself is credited to Jacob Bernoulli, who attempted to find the value of the following expression:

$$
e = \lim_{n\to\infty} \left( 1 + \frac{1}{n} \right)^n
$$


If you put $\$100$ in a bank with an annual interest rate of $10\%$ and a yearly compounding period. What you get in a year can be expressed as follows:

$$
D_t = D_0 \left(1+\frac{R}{n}\right)^{nt} = 100\times \left(1+\frac{10\%}{1}\right)^{1\times1} = 110
$$
Note that 

$\quad$ $D_0$ is the initial deposit, \
$\quad$ $D_t$ is the value of the deposit at time $t$, \
$\quad$ $R$ is the annual percentage rate (APR), \
$\quad$ $n$ is the <span style='color:red'>number of compounding periods in one year</span>, \
$\quad$ $t$ is the number of years from $D_0$ to $D_t$. 


(For a bank deposit account, the quoted interest rate often refers to as "simple interest" which ignores compounding. For example, an interest rate of $5\%$ payable every six months will be quoted as a simple interest of $10\%$ per annum in the market.)

Q: What if we compound semi-annually?

A: That is when $e$ equals 2.

$$
D_t = 100\times(1+\frac{10\%}{2})^{2\times1} = 110.25
$$



What if we compound monthly? $\rightarrow$ $n=12$

$$
D_t = 100\times(1+\frac{10\%}{12})^{12\times1} = 110.47
$$

What if we compound daily?  $\rightarrow$ $n=365$

$$
D_t = 100\times(1+\frac{10\%}{365})^{365\times1} = 110.52
$$



$\left(1+\frac{R}{n}\right)^{nt}$ can be rewritten as $\left(1+\frac{1}{\frac{n}{R}}\right)^{\frac{n}{R} \cdot R \cdot t}$. We have

$$
\left(1+\frac{1}{\frac{n}{R}}\right)^{\frac{n}{R} \cdot R \cdot t} \to e^{Rt}
$$
as $\frac{n}{R}\to \infty$.

Under continuous compounding, 

$$
\color{red} {D_t = D_0\, e^{Rt}} .
$$


```{r}
R <- 0.1 # annual interest rate
t <- 1   # total time period

n <- 2 # compound frequency in one year
100 * (1+R/n)^{n*t}

n <- 12
100 * (1+R/n)^{n*t}

n <- 365
100 * (1+R/n)^{n*t}

100 * exp(R*t)
```

Note that 

- $D_t$ under continuous compounding is always larger than those of under fixed compounding frequencies. The higher the frequency, the larger the end value $D_t$ is. This is due to the earnings from "interest-on-interest".

- $\left(1+\frac{R}{n}\right)^{n}-1$ is the effective interest rate. This is the interest rate you get as a proportion to the amount you put in and it depends on the frequency of compounding.

- Continuously compounded interest rate is the effective interest rate when compounded continuously $(n\to\infty).$

<div class = "boxed">
```{exercise, proof1}

<em>Show $\ln (1+x) \approx x$ as $x\to 0$.</em>
    
Let $f(x)=\ln (1+x)$, its first-order Taylor expansion at $x$ close to $0$ is:
    
$$
\begin{aligned}
f(x) \approx f(0) + f^\prime(0)(x-0)
\end{aligned}
$$

The first derivative of $f(x)$ is

$$
f^\prime(x) = \frac{1}{1+x}.
$$

Hence

$$
\begin{aligned}
f(x) &\approx f(0) + f^\prime(0)(x-0) \\
&= \ln(1) + 1\cdot x  \\
&= x.
\end{aligned}
$$

<span style='margin-top:-2em; float:right'>$\square$</span>
```
</div>

**From prices to returns.**

```{r}
f_name <- "data/Titlon_equity_price_2014-2023_daily.csv"
titlon_data <- read_csv(f_name)
## group by ISIN, calculate returns
titlon_group <- titlon_data %>% group_by(ISIN)
groups <- titlon_group %>% group_split()
group_key <- titlon_group %>% 
    group_keys() %>% 
    mutate(id = row_number())
group_key
```


```{r}
# subset companies with more than 3 years' data
isin_vec <- titlon_group %>% tally() %>% 
    filter(n>(252*3)) %>% 
    pull(ISIN)
id_vec <- sapply(isin_vec, function(isin) which(group_key$ISIN==isin))
# data for one equity
i <- 4
groups[[id_vec[i]]]
groups[[id_vec[i]]] %>% tail()
```



```{r}
the_group <- groups[[id_vec[i]]] 
the_group
ticker <- the_group$Symbol[1]
ticker
the_group$Name[1]

# convert to xts
library(quantmod)
the_group_xts <- xts(the_group[,c("AdjustedPrice")], order.by=the_group$Date)
# the_group_xts <- xts(the_group[,c("Price")], order.by=the_group$Date)
the_group_xts %>% str()
the_group_xts

# from daily to monthly
prices_monthly <- the_group_xts %>% to.monthly(indexAt = "last", OHLC=FALSE)
prices_monthly %>% head(20)
prices_monthly %>% tail(20)
# price plot
plot(prices_monthly, main = sprintf("Monthly Price: %s", ticker))

# calculate monthly return by hand 
simple_ret <- (diff(prices_monthly)/lag(prices_monthly)) %>% setNames("simple_return") # simple return
log_ret <- diff(log(prices_monthly)) %>% setNames("log_return")   # log return, aka, continuously compounded return
merge(prices_monthly, simple_ret, log_ret)
```


```{r}
# calculate monthly return using `PerformanceAnalytics::Return.calculate`
library(PerformanceAnalytics)
merge(Return.calculate(prices_monthly, method = "discrete"),
      Return.calculate(prices_monthly, method = "log") ) %>%
    fortify() %>% 
    setNames(c("Date", "Simple Ret", "Log Ret")) %>% 
    knitr::kable(digits = 5, escape=F, caption="Using `PerformanceAnalytics::Return.calculate`") %>%
    kable_styling(bootstrap_options = c("striped", "hover"), full_width = F, latex_options="scale_down") %>% 
    scroll_box(height = "500px")
```



--------------------------------------------------------------------------------

### Cumulative returns 

For simple return, the cumulative return from time $0$ to time $T$ is given by:

$$
r_{0:T} = \Pi_{t=1}^T (1+r_t) -1.
$$

For log return

$$
z_{0:T} = \sum_{t=1}^T z_t
$$

Note that we have to back out the simple return from the log return

$$
r_{0:T} = \exp(z_{0:T}) -1
$$



```{r simple-ret, fig.width = 8.93, fig.height = 14.51, fig.cap="Simple returns"}
return_monthly_simple <- Return.calculate(prices_monthly, method = "discrete")
return_monthly_simple[1,] <- 0
cumulative_returns_simple <- cumprod(1 + return_monthly_simple) - 1
# plot price, monthly ret, and cumu ret
par(mfrow=c(3,1))
plot(prices_monthly, main = sprintf("Monthly adjPrice: %s", ticker))
plot(return_monthly_simple, 
     main = sprintf("Monthly Return: %s", ticker))
plot(cumulative_returns_simple, 
     main = sprintf("Monthly Cumulative Return: %s", ticker))
```


```{r log-ret, fig.width = 8.93, fig.height = 14.51, fig.cap="Log returns"}
return_monthly_log <- Return.calculate(prices_monthly, method = "log")
return_monthly_log[1,] <- 0
cumulative_returns_log <- exp(cumsum(return_monthly_log)) - 1 # back out the simple return
par(mfrow=c(3,1))
plot(prices_monthly, main = sprintf("Monthly adjPrice: %s", ticker))
plot(return_monthly_log, 
     main = sprintf("Monthly Return: %s", ticker))
plot(cumulative_returns_log, 
     main = sprintf("Monthly Cumulative Return: %s", ticker))
```


The two types act very differently when it comes to aggregation.  Each has an advantage over the other:

- simple returns aggregate across assets \
The simple return of a portfolio is the weighted sum of the simple returns of the constituents of the portfolio.

- log returns aggregate across time \
The log return for a time period is the sum of the log returns of partitions of the time period.  For example, the log return for a year is the sum of the log returns of the days within the year.

------------------------------------------------------------------------

### Multiperiod returns

Multiperiod returns are the generalized case of cumulative return by allowing any holding period $k\le T$. 

The $k$-period (assuming annual frequency for now) simple return from time $t-k$ to $t$ is given by

$$
r_{t}(k) = \frac{P_t-P_{t-k}}{P_{t-k}}.
$$

It can be expressed as in terms of one-period returns as follows:

$$
\begin{aligned}
r_t(k) &= \prod_{j=0}^{k-1}(1+r_{t-j}) -1 \\
&= (1+r_t)(1+r_{t-1})\cdots (1+r_{t-k+1})-1 .
\end{aligned}
$$

We always like to talk in terms of annual performance as people like to know how much they can expect to make a year in percentage terms. That is why in most of the fund reports, you will find a standard metric called **annualized returns**. It is also known as the <span style='color:red'>*Compound Annual Growth Rate* (CAGR)</span> or the *Geometric Annual Return*.

*Annualized return* under simple returns, $r_t^A$, is given by:

$$
\begin{split}
(1+r_t^A)^k &= 1+r_t(k) \\
r_t^A &= \big(1+r_t(k) \big)^{\frac{1}{k}}-1 = \left[\prod_{j=1}^{k-1}(1+r_{t-j})\right]^{\frac{1}{k}}-1 .
\end{split}
$$


The $k$-period log return is given by

$$
z_t(k) = \ln \frac{P_t}{P_{t-k}}.
$$

It is the sum of the $k$ one-period log returns:

$$
z_t(k) = \sum_{j=0}^{k-1} z_{t-j} = z_t + z_{t-1} + \cdots + z_{t-k+1}
$$

*Annualized return* under continuously compounding, $z_t^A$, is given by:

$$
\begin{aligned}
k\,z_t^A &= z_t(k) \\
z_t^A &= \frac{1}{k}z_t(k) = \frac{1}{k} \sum_{j=0}^{k-1} z_{t-j},
\end{aligned}
$$
which is the average one-period log returns.



To summarize in one table

|               | Simple returns    | Log returns     | Back out simple returns |
| -------------------------- | :------------------------------------------------------- | :---------------------------------------------- | :---------------------------------------------- |
| Single period | $r_t=\frac{P_t}{P_{t-1}}-1$  | $z_t=\ln \frac{P_t}{P_{t-1}}$  | $r_t = \exp(z_t)-1$ |
| Multiperiod   | $r_t(k) = \prod_{j=0}^{k-1}(1+r_{t-j}) -1$   | $z_t(k) = \sum_{j=0}^{k-1} z_{t-j}$  | $r_t(k) = \exp\big(z_t(k)\big)-1$ |
| Annualized    | $r_t^A = \left[\prod_{j=0}^{k-1}(1+r_{t-j})\right]^{\frac{1}{k}}-1$ | $z_t^A = \frac{1}{k} \sum_{j=0}^{k-1} z_{t-j}$ | $r_t^A = \exp(z_t^A)-1$ |


Note that the annualized return here assumes <u>the single period returns are annual returns</u>.

___

In case of higher frequency data than annual, i.e., daily, weekly and monthly,
we have to compound by the number of periods in a year. 

- daily single period: $r_t^A = \left[\prod_{j=0}^{k-1}(1+r_{t-j})\right]^{\frac{1}{k}\cdot \color{red}{252}}-1$ for simple return, $z_t^A = \frac{252}{k} \sum_{j=0}^{k-1} z_{t-j}$ for log return.

    - Note here we used $n=252$, i.e., the number of *trading days* in a year. This is applied when reporting of trading strategy returns on a product with 5 market sessions per week. 
    - If you are calculating CAGR for FX (which is traded effectively 24/7) strategy returns for instance, it would seem fair to use $n=365$ *calendar days*.

- weekly $r_t^A = \left[\prod_{j=0}^{k-1}(1+r_{t-j})\right]^{\frac{1}{k}\cdot \color{red}{52}}-1$ for simple return, $z_t^A = \frac{52}{k} \sum_{j=0}^{k-1} z_{t-j}$ for log return.

- monthly $r_t^A = \left[\prod_{j=0}^{k-1}(1+r_{t-j})\right]^{\frac{1}{k}\cdot \color{red}{12}}-1$ for simple return, $z_t^A = \frac{12}{k} \sum_{j=0}^{k-1} z_{t-j}$ for log return. 

- quarterly $r_t^A = \left[\prod_{j=0}^{k-1}(1+r_{t-j})\right]^{\frac{1}{k}\cdot \color{red}{4}}-1$ for simple return, $z_t^A = \frac{4}{k} \sum_{j=0}^{k-1} z_{t-j}$ for log return. 


--------------------------------------------------------------------------------

### Portfolio Returns

Consider a buy-and-hold portfolio invested in $k$ different assets. The value at time $t$ is

$$
V_t = \sum_{i=1}^k n_i P_{i,t}
$$
where $n_i$ is the number of shares invested in asset $i$.


> Buy-and-hold portfolio: Portfolio weights from the initial portfolio are allowed to change over time as prices of the underlying assets change over time. In this case no rebalancing of the portfolio is done. $n_i$ is constant for each asset $i$ over the holding period. The weight increases if an asset's price increases, and decreases otherwise. This strategy is passive and does not trade further except for the initial asset allocation.


> Another trading strategy is rebalancing (monthly). This is to buy and trade at the end of each rebalance period such that your portfolio aligns with your target allocation. Regularly rebalancing a portfolio ensures that the investor maintains the desired risk and return characteristics. For instance, if the weight of a particular asset class has increased significantly due to strong performance, rebalancing involves selling a portion of that asset and reinvesting the proceeds in other assets to restore the desired portfolio weight. This is a *rebalanced portfolio*.



The simple one-period return of the portfolio is a weighted average of the returns of component stocks.

$$
r_{p,t} = \frac{V_t}{V_{t-1}}-1
= \sum_{i=1}^k w_{i,t} r_{i,t}
$$

This result is useful. We can use the property to get the expected return and variance of the portfolio as:

$$
\begin{aligned}
E[r_{p,t}] &= \sum_{i=1}^k w_{i,t} E[r_{i,t}] \\
\text{Var}[r_{p,t}] &= \sum_{i=1}^k\sum_{j=1}^k w_{i,t}\,w_{j,t}\,\text{Cov}(r_{i,t}, r_{j,t})
\end{aligned}
$$


<div class = "boxed">
```{exercise, proof2}

<em>Show $r_{p,t} = \sum_{i=1}^k w_i r_{i,t}$.</em>
    
$$
\begin{aligned}
r_{p,t} &= \frac{V_t}{V_{t-1}} -1 \\
&= \frac{\sum_{i=1}^k n_iP_{i,t}}{\sum_{j=1}^k n_jP_{j,t-1}} -1 \\
&= \sum_{i=1}^k \frac{n_iP_{i,t-1}}{\sum_{j=1}^k n_jP_{j,t-1}} \cdot \frac{P_{i,t}}{P_{i,t-1}} - 1  \qquad \text{(multiply and divide by } P_{i, t-1} )\\
&= \sum_i w_{i,t} (r_{i,t}+1) -1 \\
&= \sum_i w_{i,t} r_{i,t} \qquad (w_{i,t} \text{ sums to 1})
\end{aligned}
$$
where $w_{i,t}= \frac{n_iP_{i,t-1}}{\sum_{j=1}^k n_jP_{j,t-1}}$ is the weight of asset $i$ at time $t-1$.

<span style='margin-top:-2em; float:right'>$\square$</span>
```
</div>

Note that an asset's weight in month $t$, $w_{i,t}$, is decided by the ratio of the value of the asset to the portfolio value at the beginning of the period, i.e., at time $t-1$.

This cross-sectional additivity does not apply to log returns. In stead we have:

$$
\begin{aligned}
z_{p,t} &= \ln\,\left(\frac{V_t}{V_{t-1}}\right) \\
&= \ln \, \left(\frac{\sum_{i=1}^k n_iP_{i,t}}{\sum_{j=1}^k n_jP_{j,t-1}} \right) \\
&= \ln \, \left(\sum_{i=1}^k\frac{ n_iP_{i,t-1}}{\sum_{j=1}^k n_jP_{j,t-1}} \cdot \frac{P_{i,t}}{P_{i,t-1}} \right) \\
&= \ln \, \left(\sum_{i=1}^k w_{i,t} \frac{P_{i,t}}{P_{i,t-1}} \right) \\
&= \ln \, \left(\sum_{i=1}^k w_{i,t} \exp(z_{i,t}) \right) .
\end{aligned}
$$
The log return of the portfolio is not a linear function for the log returns of the components.

> Because the continuously compounded portfolio return is not a weighted average of the individual asset continuously compounded returns, the analysis of portfolios is typically performed using simple returns and not continuously compounded returns.


On the other hand, the log returns are additive when we consider the time series of returns:

$$
z_{p,t}(k) = \sum_{j=0}^{k-1} z_{p,t-j}.
$$
Given the expected values and the covariances of the subperiod returns, it is then easy to compute the expected value and the variance of the full period return.

In contrast, the time series additivity does not apply to simple returns.

$$
r_{p, t}(k) = \prod_{j=0}^{k-1} (1+r_{p,t-j}) -1
$$


------------------------------------------------------------------------

## Portfolio performance evaluation

We use a portfolio consisting of 2 assets as an example.

### Return

Loop through assets to calculate monthly returns from daily price data.
```{r get-monthly-return}
# calculate monthly return
data_return <- titlon_group %>%  
    group_modify( ~{
        xts(.$AdjustedPrice, order.by = .$Date) %>%
            to.monthly(indexAt="last", OHLC=FALSE) %>% 
            Return.calculate() %>% 
            data.frame() %>% 
            rownames_to_column(var="Date")
    })  %>% ungroup()
colnames(data_return)[3] <- "Return_monthly"
data_return

## equity identifiers, ensure one-to-one mapping
select <- dplyr::select
unique_id <- titlon_data %>% 
    distinct(ISIN, .keep_all = TRUE) %>% 
    select(all_of(c("SecurityId", "CompanyId", "Symbol", "ISIN",
                    "Name", "Sector")))
unique_id

## add company info
data_return <- data_return %>% 
    left_join(unique_id, by="ISIN") %>% 
    select("ISIN", "Date",
           "Symbol", "Name", "Sector", 
           "Return_monthly")

## subset complete cases
start_date <- ymd("2015-01-01")
end_date <- ymd("2022-12-31")
data_return <- data_return %>% 
    mutate(Date = ymd(Date)) %>% 
    filter(between(Date, start_date, end_date))
ISIN_vec <- data_return %>% group_by(ISIN) %>% 
    tally(sort=TRUE) %>% 
    filter(n==96) %>% 
    pull(ISIN)
ISIN_vec %>% length() # 142 complete cases
data_return <- data_return %>% filter(ISIN %in% ISIN_vec)    
data_return
```



Get sample data for two assets and create an equally-weighted portfolio of them.

```{r get-sample-data}
k <- 2 # number of asset
sample_data <- data_return %>% 
    filter(ISIN %in% c("BMG0451H1170", "NO0003079709"))
sample_data

ret_mat <- sample_data %>% pull(Return_monthly) %>% 
    matrix(ncol=k)
ret_mat %>% dim()

wts <- rep(1/k, k) 
wts
```

Calculate portfolio return manually (most concise). It is straightforward to calculate rebalanced, as the begin of period weights are always the same.
But it is a bit cumbersome to calculate buy-and-hold as we need to update the weight for each period.

Here shows an example of rebalancing monthly.

```{r}
# option 1, matrix representation
ptf_ret <- ret_mat %*% matrix(wts, ncol=1)
names(ptf_ret) <- "port_ret_manual"
ptf_ret %>% head(10)
```

Alternatively, we can use `PerformanceAnalytics` package. It provides many functions convenient for performance evaluation. We need to convert the data to `xts` before providing it as the input for `PerformanceAnalytics` functions.

```{r}
## using PerformanceAnalytics::Return.portfolio
sample_data <- sample_data %>%      # standardize date
    mutate(yrmon=as.yearmon(Date))
sample_data <- sample_data %>%  
    mutate(Date=as.Date(yrmon, frac=1))
return_xts <- sample_data %>% pull(Return_monthly) %>% 
    matrix(ncol=k) %>% 
    xts(order.by = sample_data$Date %>% unique())
colnames(return_xts) <- sample_data$Symbol %>% unique()
return_xts %>% str()

return_xts %>% 
    data.frame %>% 
    knitr::kable(digits = 5, caption = "Component asset monthly returns") %>%
    kable_styling(bootstrap_options = c("striped", "hover"), full_width = F, latex_options="scale_down") %>% 
    scroll_box(height = "500px")
```


`Return.portfolio` can do buy-and-hold and rebalanced strategies rather easily. 
We do not need to calculate the weight on our own in case of buy-and-hold.

```{r}
# buy and hold ptf
ptf_bh <- Return.portfolio(R = return_xts, weights = wts, verbose = TRUE)
# rebalanced ptf
ptf_rebal <- Return.portfolio(R = return_xts, weights = wts, rebalance_on="month", verbose = TRUE)
```


Plot the portfolio monthly returns.

```{r, out.width="100%"}
plot_data <- ptf_bh$returns %>% 
    merge(ptf_rebal$returns) %>% 
    setNames(c("buy-and-hold", "rebalance"))
plot(plot_data, multi.panel=TRUE, main="Portfolio monthly return")
```


Plot the portfolio cumulative returns.

```{r}
plot_data <- ptf_bh$returns %>% 
    merge(ptf_rebal$returns) %>% 
    as_tibble() %>% 
    mutate_all(~cumprod(1+.)) %>% 
    xts(order.by = index(ptf_bh$returns)) %>% 
    setNames(c("buy-and-hold", "rebalance"))
plot(plot_data, multi.panel=TRUE, main="Portfolio cumulative return", yaxis.same=FALSE)
```


By setting `verbose = TRUE`, it allows us to check intermediary calculations, such as contributions, weight for each asset.

Here we check the end of period weight.

```{r eop-weight, fig.width=12.45, fig.height=11.13, fig.cap="Weight of `KIT` under buy-and-hold and rebalancing."}
# plot end of period weights
eop_weight_bh <- ptf_bh$EOP.Weight
eop_weight_rebal <- ptf_rebal$EOP.Weight
par(mfrow = c(2, 1), mar = c(2, 4, 2, 2))
plot.xts(eop_weight_bh$KIT)
plot.xts(eop_weight_rebal$KIT)
```

We see that the weight of `KIT` basically skyrockets and dominates the portfolio, taking up more than $99\%$ of the portfolio.
This is due to its strong performance.

--------------------------------------------------------------------------------

Now we check the relative performance of the two assets.

```{r, out.width="100%"}
## check relative performance by calculating the equity curve
equity_curve_xts <- return_xts %>% 
    apply(2, function(col) cumprod(1 + col))
equity_curve_xts <- xts(equity_curve_xts, index(return_xts))
colnames(equity_curve_xts) <- colnames(return_xts)
plot(equity_curve_xts, multi.panel=TRUE, yaxis.same=FALSE)
```

--------------------------------------------------------------------------------


Portfolio performance attribution aggregated by year

```{r}
ptf_bh$contribution %>% 
    to.period.contributions(period = "years") %>% 
    data.frame() %>% 
    knitr::kable(digits = 4, caption = "portfolio performance attribution") %>%
    kable_styling(bootstrap_options = c("striped", "hover"), full_width = F, latex_options="scale_down")
```


--------------------------------------------------------------------------------

Q: What does the begin of period weight look like? 

A: A horizontal line at $y=50\%$.

```{r}
bop_weight_rebal <- ptf_rebal$BOP.Weight
plot(bop_weight_rebal$KIT)
```

--------------------------------------------------------------------------------

Now we build an equal-weighted portfolio consisting of 10 stocks per period, rebalanced annually. Then compute and plot portfolio returns using `PerformanceAnalytics`. This is useful when you backtest a trading strategy.


```{r}
# Backtest a hypothetical trading strategy
# Define list of selected symbols for each year (2015 to 2022, 8 yrs)
selected_symbol_by_year <- list(
  c("AURG", "RISH", "SADG", "HBC", "AKVA", "NONG", "ENTRA", "YAR", "PGS", "BMA"),
  c("YAR", "AKER", "APP", "XXL", "MSEIS", "ABL", "PSI", "RISH", "SALM", "WWI"),
  c("ATEA", "MELG", "AMSC", "KOG", "BLO", "SBVG", "ODFB", "NKR", "JAEREN", "ZAL"),
  c("ODL", "KOA", "DLTX", "NHY", "ENTRA", "KOG", "PROT", "AFG", "NAVA", "SOR"),
  c("EQNR", "DNO", "SOAG", "VVL", "KIT", "BAKKA", "WAWI", "DLTX", "AXA", "ROM"),
  c("FRO", "PHO", "DNO", "ZAL", "APP", "NHY", "MGN", "IOX", "KOA", "GJF"),
  c("RING", "GSF", "PCIB", "ABG", "VEI", "ABT", "AKPS", "SUBC", "PGS", "SAGA"),
  c("SBX", "ODF", "OPERA", "PEN", "SKUE", "SAGA", "HELG", "NOM", "MHG", "NONG")
  )
returns_xts <- data_return %>% 
    select(Date, Symbol, Return_monthly) %>%
    mutate(Date = as.Date(as.yearmon(Date), frac=1)) %>%  # standardize end of month date
    spread(key=Symbol, value=Return_monthly)
returns_xts <- returns_xts %>% xts(x=.[,-1], order.by=.[[1]])

# Construct weights xts object
dates <- index(returns_xts)
weights_list <- list()

for (i in 1:8) {
  year_start <- as.Date(paste0(2014 + i, "-01-01"))
  year_end <- as.Date(paste0(2014 + i, "-12-31"))
  period_dates <- dates[dates >= year_start & dates <= year_end]
  
  weights <- matrix(0, nrow = length(period_dates), ncol = ncol(returns_xts))
  colnames(weights) <- colnames(returns_xts)
  
  valid_symbols <- colnames(returns_xts) %in% selected_symbol_by_year[[i]]
  weights[, valid_symbols] <- 1 / 10
  
  weights_xts <- xts(weights, order.by = period_dates)
  weights_list[[i]] <- weights_xts
}

# Combine weights into one xts object
final_weights_xts <- do.call(rbind, weights_list)

# Align weights and returns
aligned_weights <- final_weights_xts[index(returns_xts)]

# Calculate portfolio return
portfolio_return <- Return.portfolio(R = returns_xts, 
                                     weights = aligned_weights, 
                                     verbose = TRUE)
```

Plot portfolio returns.

```{r fig.width=10, fig.height=9.72, fig.cap="Portfolio performance."}
charts.PerformanceSummary(portfolio_return$returns)
```

**Overall performance**

```{r}
# summary statistics
table.AnnualizedReturns(portfolio_return$returns) %>% 
    knitr::kable(digits = 4, caption = "Overall performance") %>%
    kable_styling(bootstrap_options = c("striped", "hover"), full_width = F, latex_options="scale_down")
```


**Performance by year**

```{r}
# Split portfolio return by year
portfolio_by_year <- split.xts(portfolio_return$returns, f = "years")

# Calculate annualized returns by year
library(moments)  # for skewness and kurtosis
performance_metrics <- function(x) {
  ann_ret <- table.AnnualizedReturns(x)
  skew <- skewness(na.omit(x))
  kurt <- kurtosis(na.omit(x))
  max_dd <- maxDrawdown(x)  # Maximum Drawdown
  var_95 <- VaR(x, p = 0.95, method = "historical")  # Value at Risk (VaR)
  # Conditional VaR (CVaR) / Expected Shortfall
  cvar_95 <- CVaR(x, p = 0.95, method = "historical") 
  sortino <- SortinoRatio(x)
  
  # Combine metrics
  out <- rbind(ann_ret,
               Skewness = skew,
               Kurtosis = kurt,
               MaxDrawdown = max_dd,
               VaR_95 = var_95,
               CVaR_95 = cvar_95,
               SortinoRatio = sortino)
  return(out)
}
metrics_by_year <- lapply(portfolio_by_year, performance_metrics)
metrics_by_year$all <- performance_metrics(portfolio_return$returns)
# Combine results into a single table
annualized_table <- do.call(cbind, metrics_by_year)
colnames(annualized_table) <- names(metrics_by_year)

# Print the table
annualized_table %>% 
    knitr::kable(digits = 4, caption = "Performance by year") %>%
    kable_styling(bootstrap_options = c("striped", "hover"), full_width = F, latex_options="scale_down")
```


------------------------------------------------------------------------


### Risk-adjusted returns

Excess return and Sharpe ratio.

```{r}
## load risk free and market rates
f_name <- "data/NO_Rf-OSEBX_2015-2023_monthly.csv"
rfr <- read_csv(f_name)
rfr <- rfr %>% mutate(yrmon=as.yearmon(Date))
ptf_ret3 <- ptf_rebal$returns %>% 
    data.frame(row.names = index(ptf_bh$returns)) %>% 
    as_tibble(rownames="Date") %>% 
    mutate(yrmon=as.yearmon(Date))
bind_cols(ptf_ret, ptf_ret3) # cross validate hand and computer calculations
```

Merge with risk free rate.

```{r}
colnames(ptf_ret3)[2] <- "port_ret"
ptf_ret3 <- ptf_ret3 %>% 
    left_join(rfr[,-1], by="yrmon") %>% 
    mutate(excess_ret = port_ret-rf_1month)
ptf_ret3
```


```{r fig.width=10, fig.height=9.72}
# Portfolio performance relative to benchmark
ptf_ret3[, c("Date", "port_ret", "mkt_return_monthly")] %>%
    mutate(Date = ymd(Date)) %>% 
    xts(x=.[,-1], order.by=.[[1]]) %>% 
    charts.PerformanceSummary(main = "Portfolio performance relative to benchmark")
```


--------------------------------------------------------------------------------

**Monthly mean and volatility**

- <span style='color:#0099FF'>**Arithmetic mean**</span> (AM) portfolio return $\bar{r}_{p, 0:T}$

$$
\text{Arithmetic } \bar{r}_{p, 0:T} = \frac{\sum_{t=1}^T r_{p,t}}{T}
$$

- <span style='color:#0099FF'>**Geometric mean**</span> (GM) portfolio return

    $$
    \text{Geometric } \bar{r}_{p, 0:T} = \left[\prod_{t=1}^T (1+r_{p,t}) \right] ^{\frac{1}{T}}-1
    $$

    Written as $\bar{r}_p$ in short, representing the arithmetic/geometric mean return of the portfolio from time $0$ to time $T$. 

- Arithmetic average sometimes cannot precisely reflect historical gains and losses. Suppose the original capital of $\$100$ is invested over a two-month period with 10% return in the first month and $10\%$ loss in the second month.

    - The arithmetic average return is $(10\% - 10\%)/2=0\%$, which implies that there is no change in the $\$100$ invested. However, the actual gain/loss for the investment grows from $\$100$ to $\$110$ in the first month, and drops 10% from $\$110$ to $\$99$ in the second month, indicating an actual loss of $\$1$.
    
    - The geometric return is $(1.1\times0.9)^{0.5}-1\approx -0.5\%$, indicating a loss of $-0.5\%$ per month. The geometric return that incorporates the compounding effect of growth is a better indication of historical performance. 

- Geometric mean is **smaller than or equal to** arithmetic mean and the equality holds if and only if $r_{p,1}=r_{p,2}=\cdots=r_{p,T}$. This can be proven by using **Jensen's inequality** that says, for any concave function $g(x)$, 

    $$
    E[g(x)] \le g(E[x]).
    $$

    And $\ln(x)$ is a concave function.

- Common practice is to report geometric mean portfolio return.

```{r}
# arithmetic mean monthly returns
mean(ptf_ret3$port_ret)

# geometric mean
mean.geometric(ptf_ret3$port_ret) 
prod(1+ptf_ret3$port_ret)^(1/96)-1

# mean excess return
mean(ptf_ret3$excess_ret) 
mean.geometric(ptf_ret3$excess_ret)

# standard deviation
sd(ptf_ret3$port_ret)
```


Portfolio return and standard deviation are usually published as annualized.

- Annualized arithmetic return assuming $r_{p,t}$ being monthly return

    $$
    r_{p}^A = \frac{12}{T}\sum_{t=1}^T r_{p,t} = 12\times \bar{r}_p
    $$
    
    where $\bar{r}_p$ is the arithmetic mean.

- Annualized geometric return 

    $$
    r_{p}^A = \left[\prod_{t=1}^T (1+r_{p,t}) \right]^{\frac{12}{T}}-1 = (1+\bar{r}_p)^{12}-1
    $$
    
    where $\bar{r}_p$ is the geometric mean.

- Annualized standard deviation. \
Note that in Finance, the standard deviation of returns is usually called *volatility*.

$$
\begin{aligned}
\sigma_{p}^A &= \sqrt{12} \sigma_p \\
\sigma_p^2 &= \frac{1}{T-1} \sum_{t=1}^T (r_{p,t}-\bar{r}_p)^2
\end{aligned}
$$


It is possible to use `Return.annualized`, `StdDev.annualized` from the `PerformanceAnalytics` package to get the annualized statistics, but we need to convert the portfolio return as an `xts` object. 

```{r}
# convert portfolio return to xts object
ptf_xts <- xts(ptf_ret3[,-c(1,3)], order.by=ymd(ptf_ret3$Date))
ptf_xts %>% 
    data.frame %>% 
    knitr::kable(digits = 5, caption = "Portfolio return in `xts`") %>%
    kable_styling(bootstrap_options = c("striped", "hover"), full_width = F, latex_options="scale_down") %>% 
    scroll_box(height = "500px")

# Compute the annualized arithmetic mean
Return.annualized(ptf_xts$port_ret, geometric = FALSE)
mean(ptf_ret3$port_ret)*12

# Compute the annualized geometric mean
Return.annualized(ptf_xts$port_ret, geometric = TRUE)
prod(1+ptf_ret3$port_ret)^(12/96)-1

# Compute the annualized standard deviation
StdDev.annualized(ptf_xts$port_ret)
sd(ptf_ret3$port_ret)*sqrt(12)

```


Histogram of portfolio returns.

```{r}
# histogram to check normality
chart.Histogram(
    ptf_xts$port_ret, 
    methods = c("add.density", "add.normal"),
    main = "Histogram of Returns, relative to Normal distribution"
    )
legend("topright", 
       legend = c("Portfolio", "Normal"), 
       col = c("#00008F", "#005AFF"), 
       lwd = 2, bty = "n")
```


--------------------------------------------------------------------------------

#### Skewness and Kurtosis


**Skewness** 

$\mu_3$ is the third (normalized) moment about the mean. \
It measures the asymmetry of the distribution, with symmetric distribution having $\mu_3=0$.

- $\mu_3>0$ means positively skewed, i.e., long right tail.
- $\mu_3<0$ means negatively skewed, i.e., long left tail.

$$
\mu_3 = \frac{1}{T} \frac{\sum_{t=1}^T (r_{p,t}-\bar{r}_p)^3}{\sigma_p^3}
$$

```{r fig.cap="Diagram of Skewness.", out.width="70%", echo=FALSE}
include_graphics("images/Skewness.png")
```

```{r}
# skewness
skewness(ptf_xts$port_ret)
```



**Kurtosis** 

$K_p$ is the fourth (normalized) moment about the mean. \
It measures the *tail behavior* in comparison with the normal distribution.


$$
\mu_4 = \frac{1}{T} \frac{\sum_{t=1}^T (r_{p,t}-\bar{r}_p)^4}{\sigma_p^4}
$$

The kurtosis for any normal distribution is three. For this reason, we subtract three from $\mu_4$ to get the "excess kurtosis".

- $\mu_4-3>0$ indicate a heavy-tailed distribution with higher chances of outliers.
    - Note that we cannot infer from kurtosis the shape of the peak. $\mu_4-3>0$ can associate with either a falttened (e.g., $t$-distribution, see Fig. \@ref(fig:fig-t)) or a pointy peak (Laplace distribution, see Fig. \@ref(fig:fig-Laplace)).
- $\mu_4-3<0$ indicate a light-tailed distribution with lower chances of outliers.


```{r fig-t, fig.cap="Examples of heavy-tailed distributions.", out.width="70%", echo=FALSE}
include_graphics("images/t distribution.png")
```

$t$-distribution has higher kurtosis than normal distributions. 

- Meaning that $t$-distribution has a higher probability of obtaining values that are far from the mean than a normal distribution.
- It is less peaked in the center and higher in the tails than normal distribution.
- As the degree of freedom increases, $t$-distribution approximates to normal distribution, kurtosis decreases and approximates to 3.

```{r}
set.seed(125)
rnorm(1000) %>% moments::kurtosis()
rt(1000, df=1) %>% moments::kurtosis()
rt(1000, df=2) %>% moments::kurtosis()
rt(1000, df=10) %>% moments::kurtosis()
rt(1000, df=30) %>% moments::kurtosis()
```


```{r fig-Laplace, fig.cap="**Laplace distribution**. The dotted green curve shows a normal distribution. The blue curve shows a Laplace distribution with kurtosis of 6.54. On the far left and right sides of the distribution—the tails—the space below the Laplace distribution curve (blue) is slightly thicker than the space below the normal distribution curve (green). This is an example of a heavy-tailed distribution yet with a sharper peak.", out.width="70%", echo=FALSE}
include_graphics("images/Laplace distribution.webp")
```



Distinguish from standard deviation/variance. 

Standard deviation and kurtosis are both measures of the variability of a distribution, but they are not directly related. \
Two distributions with identical means and standard deviations can have very different shapes, and kurtosis is one of the measures of that difference. 
It looks at how much of the ‘weight’ of the distribution (recall that the total weight, or the area under the curve, is 1) is sitting in the tails as opposed to the middle of the distribution. 


- Standard deviation is useful for measuring the spread.
- Kurtosis focuses on detecting outliers. 

`PerformanceAnalytics::kurtosis(x, na.rm = FALSE, method = "excess")` returns <u>excess kurtosis</u> by default. 
Need to specify `method = "moment"` in order to get the original kurtosis.

`moments::kurtosis(x)` returns the original kurtosis. Need to be compared with 3 on your own.

```{r}
# kurtosis
moments::kurtosis(ptf_xts$port_ret)
PerformanceAnalytics::kurtosis(ptf_xts$port_ret) # excess kurtosis
PerformanceAnalytics::kurtosis(ptf_xts$port_ret, method = "moment") # original kurtosis
```

`PerformanceAnalytics::table.Stats(R, ci = 0.95, digits = 4)` returns a full set of **summary statistics** that match the period of the data passed in (e.g., monthly returns will get monthly statistics, daily will be daily stats, and so on)

```{r}
# summary statistic
returns_statistics <- table.Stats(ptf_xts$port_ret)
returns_statistics %>%
    knitr::kable() %>% 
    kable_styling(bootstrap_options = c("striped", "hover"), 
                  full_width = F, latex_options="scale_down") 
```

- `SE Mean`: Standard Error of the average return. 

    $$
    \text{SE Mean} = \frac{\sigma_p}{\sqrt{T}}
    $$

- `LCL Mean`: Lower Confidence Level (LCL) of the mean, defaults to 95% confidence level.

    $$
    \text{LCL Mean} = \bar{r}_p - \text{SE Mean} \times c_{\alpha/2}
    $$
    
    where $c_{\alpha/2}$ is the critical value, i.e., $\left(1-\frac{\alpha}{2}\right)$ quantile of the $t$ distribution with $(T-1)$ degrees of freedom.

- `UCL Mean`: Upper Confidence Level (UCL) of the mean, defaults to 95% confidence level.

    $$
    \text{UCL Mean} = \bar{r}_p + \text{SE Mean} \times c_{\alpha/2}
    $$

- `Kurtosis`: Excess Kurtosis.


--------------------------------------------------------------------------------

#### Sharpe ratio

The Sharpe ratio was first introduced by @Sharpe1966 as the (arithmetic) average portfolio excess return over the sample period divided by the standard deviation of the portfolio return over that period. 
Sharpe ratio measure the portfolio's excess return per unit of standard deviation.

$$
\begin{aligned}
\text{Sharpe Ratio} &= S_p = \frac{\bar{r}_p-\bar{r}_f}{\sigma_p} \\
\text{Annualized Sharpe Ratio} &= S_p^A = \frac{\bar{r}_p-\bar{r}_f}{\sigma_p} \times \sqrt{12}
\end{aligned}
$$
where $\bar{r}_f$ is the (arithmetic) average return of the risk free rate for the time period under evaluation.

Note that consistency is required between portfolio and risk free rate for

- time period.
- frequency, i.e., monthly or yearly.

Also note that 

- The common practice is to use **arithmetic mean** in the numerator. This is referred to as "Modified Sharpe" ratio.

- When the numerator uses the geometric mean, the ratio is referred to as "Geometric Sharpe" ratio to distinguish. (Not commonly used.)


```{r}
# monthly Sharpe ratio
with(ptf_ret3, mean(excess_ret)/sd(port_ret)) 
```

Alternatively, we can use the `PerformanceAnalytics::SharpeRatio` function. \
Again in order to use it, we must provide the portfolio return as an `xts` object.

```{r}
# use arithmetic return
SharpeRatio(R=ptf_xts$port_ret, Rf=ptf_xts$rf_1month)
```


```{r}
# Compute the annualized Sharpe ratio
with(ptf_ret3, mean(excess_ret)/sd(port_ret))*sqrt(12)

ann_sharpe <- Return.annualized(ptf_xts$excess_ret, geometric = FALSE)/StdDev.annualized(ptf_xts$port_ret)
ann_sharpe

# SharpeRatio.annualized use geometric return as default
SharpeRatio.annualized(R=ptf_xts$port_ret, Rf=ptf_xts$rf_1month, geometric=FALSE)

# Geometric Sharpe is the default
SharpeRatio.annualized(R=ptf_xts$port_ret, Rf=ptf_xts$rf_1month, geometric=TRUE)
# verify with hand calculation
Return.annualized(ptf_xts$excess_ret, geometric = TRUE)/StdDev.annualized(ptf_xts$port_ret)
```

--------------------------------------------------------------------------------

#### Information ratio

While the Sharpe ratio measures the excess return as the difference between the return of the portfolio and the risk-free rate, the **information ratio**, on the other hand, measures the portfolio performance <u>against a comparable benchmark</u> rather than the risk-free rate. 

The information ratio is the active return per unit of active risk. This relates *the degree* to which an investment has beaten the benchmark to *the consistency* with which the investment has beaten the benchmark.

$$
\begin{aligned}
\text{Information Ratio} &= \text{IR}_p = \frac{\bar{r}_p-\bar{r}_m}{\sigma_{p-m}} \\
\text{Annualized Informatione Ratio} &= \text{IR}_p^A = \frac{\bar{r}_p-\bar{r}_m}{\sigma_{p-m}} \times \sqrt{12}
\end{aligned}
$$
where 

- $\bar{r}_p$ and $\bar{r}_m$ is the average return for the portfolio and the benchmark, respectively; 
- $\bar{r}_p-\bar{r}_m$ is the *active return* (or *active premium*) of the portfolio, i.e., return of portfolio in excess of the benchmark return;
- $\sigma_{p-m}$ is the *active risk* (or *tracking error*) of the portfolio, i.e., the standard deviation (volatility) of the active return.

--------------------------------------------------------------------------------

#### Beta coefficient-adjusted measures

Sharpe and Information ratios use standard deviation as the measure of portfolio risk. An alternative risk measure is the beta coefficient based on the CAPM model.

Recall that the beta coefficient can be estimated using the follow regression

$$
r_{i,\color{red}{t}} - r_{f,\color{red}{t}} = \alpha_i + \beta_i (r_{m,\color{red}{t}}-r_{f,\color{red}{t}}) + \varepsilon_{i,\color{red}{t}} .
$$
The OLS $\beta_i$ estimate can be expressed as

$$
\hat{\beta}_i = \frac{\text{Cov}(R_{m}^e, R_{i}^e)}{\text{Var}(R_{i}^e)}
$$
where 

- $R^e_i=r_i-r_f$ stands for the excess return on asset $i$, and
- $R^e_m=r_m-r_f$ stands for the excess return on the market index.


--------------------------------------------------------------------------------


**Treynor ratio** is a variant of Sharpe ratio. It substitute the standard deviation in Sharpe ratio with the beta coefficient.

The Treynor ratio is computed as

$$
\text{Treynor Ratio}_p = \frac{\bar{r}_p-\bar{r}_f}{\beta_p}
$$
Note that 

- the only relevant risk in the computation of the Treynor ratio is systematic risk. It assumes that the portfolio is fully diversified. Appropriate for diversified equity funds, the element of unsystematic risk would be negligible.

- Sharpe ratio assumes that the relevant risk is total risk (systematic and unsystematic risk), and it measures excess return per unit of total risk. It is appropriate for the portfolio that is less diversified.

- Jensen's alpha also assumes that the relevant risk is systematic risk.

--------------------------------------------------------------------------------

**Jensen's alpha** measures the average return on the portfolio in excess of what predicted by the CAPM, given the portfilio's beta and the average market return.

$$
\alpha_p =  \bar{r}_p - \left[\bar{r}_f + \beta_p(\bar{r}_m-\bar{r}_f)\right] 
$$


<span style="font-family: Courier, sans-serif; ">**Exercise**</span>

<span style="font-family: Courier, sans-serif; ">Given the following information about the return on a portfolio, the market index and risk free returns.</span>

<table style="margin-left: auto; margin-right: auto;" border="0" cellspacing="0" cellpadding="0"><colgroup><col style="width: 150px;" /><col span="3" width="80" /></colgroup>
<tbody>
<tr style="height: 23px; border-bottom: 1pt solid black;">
<td style="height: 23px;">Year</td>
<td style="width: 130px; height: 23px; text-align: right;">Portfolio</td>
<td style="width: 130px; height: 23px; text-align: right;">Market index</td>
<td style="width: 135.96875px; height: 23px; text-align: right;">Risk free rate</td>
</tr>
<tr style="height: 23px;">
<td style="height: 23px; text-align: left;" align="right">1</td>
<td class="xl63" style="width: 130px; height: 23px;" align="right">14%</td>
<td class="xl63" style="width: 130px; height: 23px;" align="right">12%</td>
<td class="xl63" style="width: 135.96875px; height: 23px;" align="right">7%</td>
</tr>
<tr style="height: 23px;">
<td style="height: 23px; text-align: left;" align="right">2</td>
<td style="width: 130px; height: 23px;" align="right">10</td>
<td style="width: 130px; height: 23px;" align="right">7</td>
<td style="width: 135.96875px; height: 23px;" align="right">7.5</td>
</tr>
<tr style="height: 19px;">
<td style="height: 19px; text-align: left;" align="right">3</td>
<td style="width: 130px; height: 19px;" align="right">19</td>
<td style="width: 130px; height: 19px;" align="right">20</td>
<td style="width: 135.96875px; height: 19px;" align="right">7.7</td>
</tr>
<tr style="height: 23px;">
<td style="height: 23px; text-align: left;" align="right">4</td>
<td style="width: 130px; height: 23px;" align="right">-8</td>
<td style="width: 130px; height: 23px;" align="right">-2</td>
<td style="width: 135.96875px; height: 23px;" align="right">7.5</td>
</tr>
<tr style="height: 23px;">
<td style="height: 23px; text-align: left;" align="right">5</td>
<td style="width: 130px; height: 23px;" align="right">23</td>
<td style="width: 130px; height: 23px;" align="right">12</td>
<td style="width: 135.96875px; height: 23px;" align="right">8.5</td>
</tr>
<tr style="height: 23px;">
<td style="height: 23px; text-align: left;" align="right">6</td>
<td style="width: 130px; height: 23px;" align="right">28</td>
<td style="width: 130px; height: 23px;" align="right">23</td>
<td style="width: 135.96875px; height: 23px;" align="right">8</td>
</tr>
<tr style="height: 23px;">
<td style="height: 23px; text-align: left;" align="right">7</td>
<td style="width: 130px; height: 23px;" align="right">20</td>
<td style="width: 130px; height: 23px;" align="right">17</td>
<td style="width: 135.96875px; height: 23px;" align="right">7.3</td>
</tr>
<tr style="height: 23.5px;">
<td style="width: 130px; height: 23.5px; text-align: left;" align="right">8</td>
<td style="width: 130px; height: 23.5px;" align="right">14</td>
<td style="width: 130px; height: 23.5px;" align="right">20</td>
<td style="width: 135.96875px; height: 23.5px;" align="right">7</td>
</tr>
<tr style="height: 23px;">
<td style="height: 23px; text-align: left;" align="right">9</td>
<td style="width: 130px; height: 23px;" align="right">-9</td>
<td style="width: 130px; height: 23px;" align="right">-5</td>
<td style="width: 135.96875px; height: 23px;" align="right">7.5</td>
</tr>
<tr style="height: 23px; border-bottom: 1pt solid black;">
<td style="height: 23px; text-align: left;" align="right">10</td>
<td style="width: 130px; height: 23px;" align="right">19</td>
<td style="width: 130px; height: 23px;" align="right">16</td>
<td style="width: 135.96875px; height: 23px;" align="right">8</td>
</tr>
<tr style="height: 23px;">
<td style="height: 23px;">Average</td>
<td class="xl64" style="width: 130px; height: 23px;" align="right">13%</td>
<td class="xl64" style="width: 130px; height: 23px;" align="right">12%</td>
<td class="xl64" style="width: 135.96875px; height: 23px;" align="right">7.6%</td>
</tr>
<tr style="height: 23px; border-bottom: 1pt solid black;">
<td style="height: 23px;">Standard deviation</td>
<td class="xl64" style="width: 130px; height: 23px;" align="right">12.39%</td>
<td class="xl64" style="width: 130px; height: 23px;" align="right">9.43%</td>
<td class="xl64" style="width: 135.96875px; height: 23px;" align="right">0.47%</td>
</tr>
<tr style="height: 23px;">
<td style="height: 23px;">Cov($r_p$, $r_m$)</td>
<td style="width: 130px; height: 23px;" align="right">0.0107</td>
<td style="width: 130px; height: 23px;">&nbsp;</td>
<td style="width: 135.96875px; height: 23px;">&nbsp;</td>
</tr>
</tbody>
</table>


&nbsp;

<div style="font-family: Courier, sans-serif; ">
1. Calculate the beta.

$$
\beta_p = \frac{\text{Cov}(r_p, r_m)}{\text{Var}(r_m)} = \frac{0.0107}{9.43\%^2} = 1.203
$$

2. Calculate the Sharpe ratio. 

$$
S_p = \frac{\bar{r}_p-\bar{r}_f}{\sigma_p} = \frac{(13-7.6)\%}{12.39\%} = 0.436
$$

3. Calculate the Treynor ratio.

$$
T_p = \frac{\bar{r}_p-\bar{r}_f}{\beta_p} = \frac{(13-7.6)\%}{1.203} = 0.0449
$$


4. Calculate Jensen’s Alpha.

$$
\alpha_p =  \bar{r}_p - \left[\bar{r}_f + \beta_p(\bar{r}_m-\bar{r}_f)\right] = 13\% - 7.6\% - 1.203\times (12-7.6)\% = 0.107\% 
$$

</div>

&nbsp;

--------------------------------------------------------------------------------

#### M-squared 

The M-squared ($M^2$) measure is first introduced by Franco Modigliani.
$M^2$ provides a direct comparison between the leverage-adjusted portfolio and the market portfolio.

A managed portfolio $p$ is mixed with a position in the risk free asset to make the "leverage-adjusted" (or "adjusted" in short) portfolio have the same volatility as the market.
Suppose the managed portfolio p has a total variability equal to $1.5\times \sigma_m$. The "adjusted" portfolio $p^*$ is found by investing a weight $w$ in $p$ and a weight $(1 − w)$ in the risk free asset, such that the portfolio has the same standard deviation as the market:

$$
\begin{aligned}
r_{p^*} &= w\, r_p + (1-w)\, r_f \\
\sigma_{p^*} &= w\sigma_p + (1-w)\sigma_{r_f} = w\sigma_p + (1-w)\cdot 0 = w\sigma_p 
\end{aligned}
$$
Let 

$$
\sigma_{p^*} = \sigma_m ,
$$
we have

$$
w\sigma_p = \sigma_m \Rightarrow w=\frac{\sigma_m}{\sigma_p} = \frac{\sigma_m}{1.5\sigma_m} = \frac{2}{3}
$$
By investing two thirds in $p$ and one third in the risk free asset $r_f$, achieve the same volatility as the market.

Since $P^∗$ and $m$ have the same volatility, we may compare their returns simply by calculating the difference:

$$
M_p^2 = r_{p^*} - r_m .
$$



--------------------------------------------------------------------------------


### Downside risk measures

When the return distribution is asymmetric (skewed), investors use additional risk measures that focus on describing the potential losses.

- The **Semi-Deviation** is the calculation of the variability of returns below the mean return.
$$
\begin{aligned}
\text{Semi } \sigma_p &= \sqrt{\frac{1}{n}\textstyle \sum_{t=1}^T \big[\min(r_{p,t}-\bar{r}_p, 0)\big]^2 } \\
\text{Annualized Semi } \sigma_p^A &= \sqrt{\frac{1}{n}\textstyle \sum_{t=1}^T \big[\min(r_{p,t}-\bar{r}_p, 0)\big]^2 } \times \sqrt{12}
\end{aligned}
$$
where $n$ is either the number of observations of the entire series or the number of observations in the subset of the series falling below the average.

- **Value-at-Risk** (VaR) measures the potential loss in value of a risky asset or portfolio over a defined period for a given confidence interval. It corresponds to a probability $p$, which is a confidence level.

    A $p$ VaR means that the probability of a loss greater than VaR is (at most) $(p)$ while the probability of a loss less than VaR is (at least) $1-p$.

    -  For example, a one-day $5\%$ VaR of $\$1$ million implies the portfolio has a $5\%$ chance that the value of the asset drops more than $\$1$ million over one day. In other words, there is a $95\%$ probability that the asset makes a profit or lose less than $\$1$ million over a day.

    -  Different conventions are used for $p$. You can tell by the magnitude whether it refers to a confidence level or a significance level. For instance, sometimes you see $95\%$ VaR (confidence level) and $5\%$ VaR (significance level).

    - To obtain a sample estimate of $5\%$ VaR, we sort the observations from high to low. The VaR is the return at the $5$th percentile of the empirical sample distribution.
    
    - More formally,
      $$
      \text{VaR}(\alpha) = -F^{-1}(\alpha)
      $$
      where $F(\cdot)$ is the cdf of the portfolio return $r_p$.
      

- The **expected shortfall** (ES) is the expected value of the loss, given the loss is greater than the VaR. 

$$
\text{ES}(\alpha) = E[r_p \vert r_p \leq F^{-1}(\alpha)]
$$

- VaR is the most optimistic measure of worst-case scenarios as it takes the smallest loss of all these cases, while ES informs the magnitudes of potential losses given that the loss is greater than the VaR.


```{r}
## downside risk measures
# Calculate the SemiDeviation
SemiDeviation(ptf_xts$port_ret)
sd(ptf_xts$port_ret)

# Calculate the value at risk, p is the confidence level
VaR(ptf_xts$port_ret, p=.95) # 95% VaR
VaR(ptf_xts$port_ret, p=.99) # 99% VaR

# Calculate the expected shortfall
ES(ptf_xts$port_ret, p=.95)
ES(ptf_xts$port_ret, p=.99)
```

The other popular downside risk estimate, the **maximum drawdown** (MDD) of the portfolio, measures the largest loss from peak to trough over the examination period.

The maximum drawdown of the portfolio indicates the maximum possible loss investors have ever experienced over the examination period.

$$
MDD = \frac{LP-PV}{PV}
$$

- where $LP$ is the lowest value after peak value, this is also called "Trough Value";
- $PV$ is the peak value.

```{r}
# Table of drawdowns
maxDrawdown(ptf_xts$port_ret)
table.Drawdowns(ptf_xts$port_ret)
```


```{r}
# Plot of drawdowns
chart.Drawdown(ptf_xts$port_ret)
```


--------------------------------------------------------------------------------

### Rolling performance

Rolling performance is typically used as a way to assess stability of a return stream.


A rolling window of 12 months is **NOT** the same as annually. 

- Rolling window of 12 mons: The window "rolls" forward one month at a time. The data frequency is monthly. 

    For example, it computes return from Jan–Dec 2015, then Feb 2015–Jan 2016, then Mar 2015–Feb 2016, and so on. This gives you a smoother, more continuous view of how performance evolves over time.

- Annual performance calculates returns or metrics strictly once per calendar year (e.g., Jan–Dec 2015, Jan–Dec 2016). The data frequency is annually. 

    Each year is treated as a discrete block. There's no overlap between years.


**Key differences**:

| Aspect               | Rolling 12-Month Window           | Annual (Calendar Year)            |
|:---------------------|:----------------------------------|:----------------------------------|
| Frequency            | Monthly                           | Yearly                            |
| Overlapping Periods  | Yes                               | No                                |
| Smoothness           | Smoother trends                   | Step-wise, discrete jumps         |
| Use Case             | Trend analysis, risk over time    | Year-by-year comparison           |
| Number of Observations | Higher                          | Lower                             |


`PerformanceAnalytics::chart.RollingPerformance(R, width = 12, FUN = "Return.annualized")` provides a way to display different metrics, e.g., returns, standard deviation, Sharpe ratio, over rolling time periods.

- `width`: number of periods to apply rolling function window over.
- `FUN`: any function that can be evaluated using a single set of returns.

```{r}
## rolling annualized mean
chart.RollingPerformance(R = ptf_xts$port_ret, width = 12, FUN = "Return.annualized")
## rolling annualized volatility
chart.RollingPerformance(R = ptf_xts$port_ret, width = 12, FUN = "StdDev.annualized")
## rolling annualized Sharpe ratio
chart.RollingPerformance(R = ptf_xts$port_ret, width = 12, FUN = "SharpeRatio.annualized", Rf=ptf_xts$rf_1month)
```


Three-in-one rolling performance charts can be created using `charts.RollingPerformance`.

```{r}
charts.RollingPerformance(R = ptf_xts$port_ret, width = 12, Rf=ptf_xts$rf_1month)
```




--------------------------------------------------------------------------------

### CAPM-related metrics

`table.SFM` (or `table.CAPM`) creates a table of **CAPM-Related Measures**. SFM stands for Single Factor Model.

```{r}
with(ptf_xts,
    table.SFM(
        Ra = port_ret,
        Rb = mkt_return_monthly, 
        Rf = rf_1month,
        digits = 4)
    ) %>% 
    setNames("Portfolio performance") %>% 
    knitr::kable(caption = "Table of CAPM-related statistics") %>%
    kable_styling(bootstrap_options = c("striped", "hover"), full_width = F, latex_options="scale_down") 
```

- `Beta`: beta coefficient of CAPM
- `Beta +`: `CAPM.beta.bull` is a regression for only positive market returns, which can be used to understand the behavior of the asset or portfolio in positive or 'bull' markets.
- `Beta -`: `CAPM.beta.bear` provides the calculation on negative market returns.
- `Active Premium`: performance premium provided by an investment over a passive strategy (the benchmark), which is the investment's annualized return minus the benchmark's annualized return. Also called "Active Return."

$$
\text{Active Premium} = \bar{r}_p-\bar{r}_m
$$

- `Tracking Error`: the unexplained portion of the investment's performance relative to a benchmark, defined as the standard deviation of the active return.

    $$
    \begin{aligned}
    \text{Tracking Error} &= \sigma_{p-m} \\
    &= \sqrt{\frac{\sum(r_{p}-r_{m})^{2}}{T-1}} \times \sqrt{\text{scale}}
    \end{aligned}
    $$
    
    $\text{scale}$ is the number of periods in a year (daily scale = 252, weekly scale = 52, monthly scale = 12, quarterly scale = 4, annually sacle = 1).

- `Information Ratio` is defined as the `Active Premium` divided by the `Tracking Error`.

$$
\begin{aligned}
\text{IR}_p &= \frac{\text{Active Premium}}{\text{Tracking Error}} \\
&= \frac{\bar{r}_p-\bar{r}_m}{\sigma_{p-m}}
\end{aligned}
$$

--------------------------------------------------------------------------------

**Risk decomposition** of the return distribution. 

- Specific risk is the annualized standard deviation of the error term in the CAPM regression equation.

- Systematic risk, as defined by Bacon (2008), is the product of beta by market risk.

    $$
    \sigma_s = \beta * \sigma_m
    $$

    Market risk, $\sigma_m$, is the annualized standard deviation of the benchmark. $\beta$ is the regression beta.

- Total risk is defined as

$$
\text{Total Risk} = \sqrt{\text{Systematic Risk}^2 + \text{Specific Risk}^2}
$$


`table.SpecificRisk` provide a table of specific risk, systematic risk and total risk.

```{r}
# Risk decomposition
with(ptf_xts,
     table.SpecificRisk(
        Ra = port_ret,
        Rb = mkt_return_monthly, 
        Rf = rf_1month,
        digits = 4)
     )
```



--------------------------------------------------------------------------------


### References


[heavy-tailed]: https://stats.stackexchange.com/a/172532















